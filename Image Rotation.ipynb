{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Idea:\n",
    "# /content/gdrive/My Drive/Colab Notebooks/\n",
    "\n",
    "# Plan\n",
    "# 1. Add Background to Image dependent on image size (choose from x different backgrounds)\n",
    "# 2. Add some more distortions\n",
    "# 3. Rotate and sheer image\n",
    "# 4. Rescale images to fixed size.\n",
    "# 5. Write as generator\n",
    "# 6. Write CNN which predicts 2 angles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "from imgaug import augmenters as iaa\n",
    "import imgaug as ia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_foreground_size = 300\n",
    "scaler = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_background_img(foreground, background, max_foreground_size, scaler):\n",
    "    width = foreground.size[0]\n",
    "    height = foreground.size[1]\n",
    "\n",
    "    if(width > height):\n",
    "        percentage = max_foreground_size/width\n",
    "        max_size = int(width*scaler*percentage)\n",
    "    else:\n",
    "        percentage = max_foreground_size/height\n",
    "        max_size = int(height*scaler*percentage)\n",
    "        \n",
    "#     print(width, height, percentage)\n",
    "\n",
    "    foreground = foreground.resize((int(width*percentage), int(height*percentage)), Image.ANTIALIAS)\n",
    "\n",
    "    background = background.resize((max_size, max_size), Image.ANTIALIAS)\n",
    "\n",
    "    margin_w = int((background.size[0]-foreground.size[0])/2)\n",
    "    margin_h = int((background.size[1]-foreground.size[1])/2)\n",
    "\n",
    "    # foreground.show()\n",
    "    background.paste(foreground, (margin_w, margin_h))\n",
    "#     background.show()\n",
    "\n",
    "    return background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_image(foreground, background, max_foreground_size, scaler):\n",
    "    # load image with background\n",
    "    open_cv_image = np.array(add_background_img(foreground, background, max_foreground_size, scaler).convert('RGB'))\n",
    "\n",
    "    # Convert RGB to BGR\n",
    "    open_cv_image = open_cv_image[:, :, ::-1].copy() \n",
    "\n",
    "    # define augmentations\n",
    "    rotation = random.uniform(-85,85)\n",
    "    shear = random.uniform(-10,10)\n",
    "\n",
    "    # 2. Add some more distortions\n",
    "    blur_aug = ia.augmenters.blur.MotionBlur(k=(3,10), angle=(0, 360), direction=(-1.0, 1.0))\n",
    "    \n",
    "    # 3. Rotate and sheer image\n",
    "    rotate_aug = ia.augmenters.geometric.Affine(rotate=rotation)\n",
    "    shear_aug = ia.augmenters.geometric.Affine(shear=shear)\n",
    "    \n",
    "    # exectue augmentation\n",
    "    new_img = blur_aug.augment_image(open_cv_image)\n",
    "    new_img = rotate_aug.augment_image(new_img)\n",
    "    new_img = shear_aug.augment_image(new_img)\n",
    "\n",
    "    # show\n",
    "    img = cv2.cvtColor(new_img, cv2.COLOR_BGR2RGB)\n",
    "    img = Image.fromarray(img)\n",
    "#     img.show()\n",
    "\n",
    "    # crop image\n",
    "    rand_scaler = scaler*random.uniform(0.7,1.3)\n",
    "#     print(\"rand_scaler\", rand_scaler)\n",
    "    crop_side_percentage = (rand_scaler-1)/(2*rand_scaler)\n",
    "\n",
    "    area = (\n",
    "        img.size[0]*crop_side_percentage, # width left\n",
    "        img.size[1]*crop_side_percentage, # height top\n",
    "        img.size[0]*(1-crop_side_percentage), # width right\n",
    "        img.size[1]*(1-crop_side_percentage), # height bottom\n",
    "    )\n",
    "    cropped_img = img.crop(area)\n",
    "#     cropped_img.show()\n",
    "    \n",
    "    return cropped_img, rotation, shear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_folder = \"invoice_img_data\"\n",
    "background_img_folder = \"background_img\"\n",
    "\n",
    "input_img_names = [x for x in os.listdir(input_data_folder) if \"_label\" not in x and \".png\" in x]\n",
    "background_img_names = [\n",
    "    x for x in os.listdir(background_img_folder) if \"_label\" not in x and \".png\" in x or \".jpg\" in x or \".jpeg\" in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300, 23)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_img_names), len(background_img_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('out_244.png',\n",
       " 'mobile-phone-with-blank-screen-on-wooden-table-background-top-view-with-copy-space_1253-984.jpg')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choice(input_img_names), random.choice(background_img_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test augmentation\n",
    "for i in range(5):\n",
    "    background = Image.open(os.path.join(background_img_folder, random.choice(background_img_names)))\n",
    "    foreground = Image.open(os.path.join(input_data_folder, random.choice(input_img_names)))\n",
    "\n",
    "    final_img, rotation, shear = augment_image(foreground, background, max_foreground_size, scaler)\n",
    "    final_img.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:This caffe2 python run does not have GPU support. Will run in CPU only mode.\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# https://stackoverflow.com/questions/42480111/model-summary-in-pytorch\n",
    "from torchsummary import summary\n",
    "\n",
    "# https://github.com/lanpa/tensorboardX\n",
    "from tensorboardX import SummaryWriter\n",
    "writer = SummaryWriter(\"logs/image_rotation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "# device = torch.device('cuda') # Uncomment this to run on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class depthwise_separable_conv(nn.Module):\n",
    "    def __init__(self, nin, nout, ksize, padd):\n",
    "        super(depthwise_separable_conv, self).__init__()\n",
    "        self.depthwise = nn.Conv2d(nin, nin, kernel_size=ksize, padding=padd, groups=nin)\n",
    "        self.pointwise = nn.Conv2d(nin, nout, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.depthwise(x)\n",
    "        out = self.pointwise(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv_max_step(nn.Module):\n",
    "    def __init__(self, nin, nout, ksize, padd):\n",
    "        super(conv_max_step, self).__init__()\n",
    "        self.conv = depthwise_separable_conv(nin, nout, ksize, padd)\n",
    "        self.batchn = nn.BatchNorm2d(nout)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxp = nn.MaxPool2d(2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.batchn(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxp(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, max_img_size, nchannel, nclasses, ):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        nin = nchannel\n",
    "        nout = int(nin*2)\n",
    "        self.cm1 = conv_max_step(nin, nout, 7, 3)\n",
    "        max_img_size = max_img_size/2\n",
    "\n",
    "        nin = nout\n",
    "        nout = int(nin*2)\n",
    "        self.cm2 = conv_max_step(nin, nout, 3, 1)\n",
    "        max_img_size = max_img_size/2\n",
    "\n",
    "        nin = nout\n",
    "        nout = int(nin*2)\n",
    "        self.cm3 = conv_max_step(nin, nout, 3, 1)\n",
    "        max_img_size = max_img_size/2\n",
    "\n",
    "        nin = nout\n",
    "        nout = int(nin*2)\n",
    "        self.cm4 = conv_max_step(nin, nout, 3, 1)\n",
    "        max_img_size = int(max_img_size/2)\n",
    "\n",
    "        self.lin_dim = nout*max_img_size*max_img_size\n",
    "        self.fc = nn.Linear(in_features=self.lin_dim, out_features=nclasses)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.cm1(x)\n",
    "        x = self.cm2(x)\n",
    "        x = self.cm3(x)\n",
    "        x = self.cm4(x)\n",
    "        x = x.view(-1, self.lin_dim)\n",
    "        out = self.fc(x)\n",
    "       \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_data_generator(input_img_names, background_img_names, itr, batch_size):\n",
    "    inpu = []\n",
    "    rotation = []\n",
    "    shear = []\n",
    "\n",
    "    # put into generator function for evaluation\n",
    "    for img_name in input_img_names[itr*batch_size:(itr+1)*batch_size]:\n",
    "        background_name = random.choice(background_img_names)\n",
    "\n",
    "        foreground = Image.open(os.path.join(input_data_folder, img_name))\n",
    "        background = Image.open(os.path.join(background_img_folder, background_name))\n",
    "\n",
    "        curr_img, rot, she = augment_image(foreground, background, max_foreground_size, scaler)\n",
    "\n",
    "        curr_img = curr_img.resize((max_img_size, max_img_size), Image.ANTIALIAS)\n",
    "        curr_img = np.array(curr_img)\n",
    "\n",
    "        inpu.append(curr_img)\n",
    "        rotation.append(rot)\n",
    "        shear.append(she)\n",
    "\n",
    "    # move channel to second index position\n",
    "    inpu = np.swapaxes(np.array(inpu), 3, -3)\n",
    "    X = torch.from_numpy(inpu).float()\n",
    "\n",
    "    y = np.transpose(np.vstack([rotation, shear]))\n",
    "    y = torch.from_numpy(y).float()\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  2%|▏         | 1/50 [00:26<21:49, 26.72s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  4%|▍         | 2/50 [00:53<21:29, 26.86s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  6%|▌         | 3/50 [01:31<23:27, 29.94s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  8%|▊         | 4/50 [02:00<22:56, 29.92s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 10%|█         | 5/50 [02:44<25:25, 33.89s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 12%|█▏        | 6/50 [03:16<24:38, 33.59s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 14%|█▍        | 7/50 [03:50<24:02, 33.55s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 16%|█▌        | 8/50 [04:20<22:43, 32.47s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 18%|█▊        | 9/50 [04:55<22:47, 33.35s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 20%|██        | 10/50 [05:26<21:37, 32.44s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 22%|██▏       | 11/50 [05:54<20:23, 31.38s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 24%|██▍       | 12/50 [06:23<19:17, 30.46s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 26%|██▌       | 13/50 [06:54<18:54, 30.66s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 28%|██▊       | 14/50 [07:27<18:47, 31.33s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 30%|███       | 15/50 [07:58<18:19, 31.41s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 32%|███▏      | 16/50 [08:27<17:20, 30.61s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 34%|███▍      | 17/50 [08:59<17:05, 31.06s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 36%|███▌      | 18/50 [09:28<16:14, 30.45s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 38%|███▊      | 19/50 [09:58<15:36, 30.20s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 40%|████      | 20/50 [10:30<15:18, 30.61s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 42%|████▏     | 21/50 [10:59<14:37, 30.25s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 44%|████▍     | 22/50 [11:28<13:58, 29.96s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 46%|████▌     | 23/50 [11:58<13:25, 29.84s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 48%|████▊     | 24/50 [12:26<12:47, 29.51s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 50%|█████     | 25/50 [12:55<12:12, 29.31s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 52%|█████▏    | 26/50 [13:23<11:32, 28.86s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 54%|█████▍    | 27/50 [14:00<12:01, 31.37s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 56%|█████▌    | 28/50 [15:48<19:54, 54.31s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 58%|█████▊    | 29/50 [17:39<24:58, 71.34s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 60%|██████    | 30/50 [18:32<21:55, 65.79s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 62%|██████▏   | 31/50 [19:01<17:16, 54.58s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 64%|██████▍   | 32/50 [19:28<13:53, 46.31s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 66%|██████▌   | 33/50 [19:55<11:30, 40.60s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 68%|██████▊   | 34/50 [20:24<09:54, 37.18s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 70%|███████   | 35/50 [20:52<08:36, 34.46s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 72%|███████▏  | 36/50 [21:19<07:30, 32.19s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 74%|███████▍  | 37/50 [21:50<06:54, 31.88s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 76%|███████▌  | 38/50 [22:17<06:05, 30.42s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 78%|███████▊  | 39/50 [22:46<05:28, 29.87s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 80%|████████  | 40/50 [23:15<04:58, 29.81s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 82%|████████▏ | 41/50 [23:48<04:35, 30.63s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 84%|████████▍ | 42/50 [24:22<04:12, 31.53s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 86%|████████▌ | 43/50 [24:52<03:37, 31.10s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 88%|████████▊ | 44/50 [25:20<03:00, 30.16s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 90%|█████████ | 45/50 [25:48<02:27, 29.57s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 92%|█████████▏| 46/50 [26:14<01:54, 28.57s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 94%|█████████▍| 47/50 [26:44<01:27, 29.01s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 96%|█████████▌| 48/50 [27:14<00:58, 29.39s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 98%|█████████▊| 49/50 [27:42<00:28, 28.88s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 50/50 [28:09<00:00, 28.36s/it]\u001b[A\n",
      "\u001b[A"
     ]
    }
   ],
   "source": [
    "max_epochs = 50\n",
    "batch_size = 254\n",
    "learning_rate = 1e-4\n",
    "\n",
    "n_batches = int(np.ceil(len(input_img_names)/batch_size))\n",
    "\n",
    "max_img_size = 64\n",
    "inp_channels = 3\n",
    "nclasses = 2\n",
    "\n",
    "# model\n",
    "model = Model(max_img_size, inp_channels, nclasses)\n",
    "# loss\n",
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in tqdm(range(max_epochs)):\n",
    "#     print(\"epoch: %i\" % epoch)\n",
    "    for itr in range(n_batches):\n",
    "        # get training data from generator\n",
    "        X, y = training_data_generator(input_img_names, background_img_names, itr, batch_size)\n",
    "\n",
    "        # Forward pass: compute predicted y by passing x to the model.\n",
    "        y_pred = model.forward(X)\n",
    "\n",
    "        # Compute and print loss.\n",
    "        loss = loss_fn(y_pred, y)\n",
    "\n",
    "        # Zero the gradients before running the backward pass.\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Backward pass: compute gradient of the loss.\n",
    "        loss.backward()\n",
    "\n",
    "        # Calling the step function on an Optimizer makes an update to its parameters\n",
    "        optimizer.step()\n",
    "\n",
    "#     print(loss.item())\n",
    "    writer.add_scalar(\"total_loss\", loss.item(), epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sudo Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_image(final_img, shear, rotation):\n",
    "    shear_aug_ = ia.augmenters.geometric.Affine(shear=-shear)\n",
    "    rotate_aug_ = ia.augmenters.geometric.Affine(rotate=-rotation)\n",
    "\n",
    "    reverse_img = np.array(final_img.convert('RGB'))\n",
    "\n",
    "    # Convert RGB to BGR\n",
    "    reverse_img = reverse_img[:, :, ::-1].copy()\n",
    "\n",
    "    # reverse augmentation\n",
    "    reverse_img = shear_aug_.augment_image(reverse_img)\n",
    "    reverse_img = rotate_aug_.augment_image(reverse_img)\n",
    "\n",
    "    # show\n",
    "    img = cv2.cvtColor(reverse_img, cv2.COLOR_BGR2RGB)\n",
    "    img = Image.fromarray(img)\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_image(final_img).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(batch_size):\n",
    "    Image.fromarray(inpu[i]).show()\n",
    "    correct_image(Image.fromarray(inpu[i]), shear[i], rotation[i]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image with background\n",
    "open_cv_image = np.array(add_background_img(foreground, background, max_foreground_size, scaler).convert('RGB'))\n",
    "\n",
    "# Convert RGB to BGR\n",
    "open_cv_image = open_cv_image[:, :, ::-1].copy() \n",
    "\n",
    "# augment image (rotate)\n",
    "# define rotation\n",
    "rotation = random.uniform(-85,85)\n",
    "shear = random.uniform(-10,10)\n",
    "# aug = iaa.Affine(rotate=45) # rotation\n",
    "\n",
    "# rotate_aug = ia.augmenters.geometric.Affine(rotate=rotation)\n",
    "# shear_aug = ia.augmenters.geometric.Affine(shear=shear)\n",
    "\n",
    "# exectue augmentation\n",
    "# new_img = rotate_aug.augment_image(open_cv_image)\n",
    "# new_img = shear_aug.augment_image(new_img)\n",
    "\n",
    "new_img = blur.augment_image(open_cv_image)\n",
    "\n",
    "# show\n",
    "img = cv2.cvtColor(new_img, cv2.COLOR_BGR2RGB)\n",
    "img = Image.fromarray(img)\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
